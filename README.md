<p align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-blue?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/Platform-Windows-0078D6?style=for-the-badge&logo=windows&logoColor=white" alt="Windows"/>
  <img src="https://img.shields.io/badge/AI-Groq%20LLM-orange?style=for-the-badge&logo=ai&logoColor=white" alt="AI"/>
  <img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="License"/>
</p>

<h1 align="center">ğŸ¤– Auto-BOT</h1>
<h3 align="center">Voice-Controlled Desktop Automation with AI</h3>

<p align="center">
  <em>Transform your Windows PC into an intelligent assistant that executes complex tasks through natural voice commands</em>
</p>

---

## ğŸ¯ Overview

**Auto-BOT** is a sophisticated voice-controlled desktop automation system that leverages Large Language Models (LLMs) to understand natural language commands and translate them into precise desktop actions. Built with a modular OOP architecture, it combines speech recognition, AI-powered intent parsing, and OS-level automation.

### âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| ğŸ¤ **Natural Language Processing** | Speak naturally - the AI understands context and intent |
| ğŸ§  **LLM-Powered Brain** | Uses Groq's Llama 3.1 for intelligent command parsing |
| ğŸ–¥ï¸ **Full Desktop Control** | Launch apps, manage files, control browser, and more |
| ğŸµ **Music Integration** | Play any song via voice command |
| ğŸ“¸ **Screenshot Capture** | Hands-free screen capture |
| ğŸ“Š **System Monitoring** | Real-time CPU, memory, and battery reports |
| ğŸ¨ **Sci-Fi HUD Interface** | Immersive tactical-style GUI |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AUTO-BOT SYSTEM                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚   GUI Layer  â”‚â”€â”€â”€â–¶â”‚  Bot Engine  â”‚â”€â”€â”€â–¶â”‚   Nova OS    â”‚       â”‚
â”‚  â”‚   (Tkinter)  â”‚    â”‚  (Async I/O) â”‚    â”‚  (Executor)  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                   â”‚                   â”‚                â”‚
â”‚         â–¼                   â–¼                   â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Voice Input  â”‚    â”‚  Nova Brain  â”‚    â”‚  OS Actions  â”‚       â”‚
â”‚  â”‚  (Google SR) â”‚    â”‚  (Groq LLM)  â”‚    â”‚ (PyAutoGUI)  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

| Module | Purpose | Technologies |
|--------|---------|--------------|
| `app/gui.py` | Sci-Fi tactical interface with real-time status | Tkinter, Canvas Graphics |
| `app/main.py` | Async bot engine, voice capture, TTS | AsyncIO, Edge-TTS, Pygame |
| `app/nova_brain.py` | LLM integration for intent recognition | Groq API, Llama 3.1 |
| `app/nova_os.py` | OS-level automation (OOP design) | PyAutoGUI, PyWin32, PSUtil |
| `app/nova_actions.py` | Action library (functional design) | Subprocess, OS |

---

## ğŸš€ Quick Start

### Prerequisites

- Windows 10/11
- Python 3.8+
- Microphone
- Internet connection
- [Groq API Key](https://console.groq.com) (free tier available)

### Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/Auto-BOT.git
cd Auto-BOT

# Create virtual environment
python -m venv .venv
.venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Configure environment
copy .env.example .env
# Edit .env and add your GROQ_API_KEY
```

### Running the Application

```bash
# GUI Mode (recommended)
python -m app.gui

# Console Mode (legacy)
python -m app.main
```

---

## ğŸ® Usage Examples

### Voice Commands

| Command | Action |
|---------|--------|
| *"Open Notepad"* | Launches Notepad |
| *"Go to YouTube"* | Opens YouTube in browser |
| *"Play Blinding Lights"* | Plays song on YouTube |
| *"Create a folder called Projects on Desktop"* | Creates folder + opens it |
| *"Take a screenshot"* | Captures screen to Desktop |
| *"Status report"* | Reports CPU, memory, battery |
| *"Download VLC"* | Opens VLC download page |
| *"Initiate coding mode"* | Opens VS Code + GitHub + Lo-Fi music |

### Multi-Step Commands

The AI breaks down complex requests automatically:

```
User: "Open Notepad and write a poem about coding"

AI Plan:
1. LAUNCH_SYS â†’ notepad
2. TYPE_STRING â†’ "Code flows like rivers..."
3. RESPONSE â†’ "Typed poem in Notepad"
```

---

## ğŸ› ï¸ Technical Highlights

### AI Integration
- **Model**: Llama 3.1 8B Instant via Groq
- **Response Format**: Structured JSON action plans
- **Temperature**: 0.0 for deterministic outputs

### Voice Processing
- **Speech Recognition**: Google Speech API
- **Text-to-Speech**: Microsoft Edge TTS (neural voices)
- **Audio**: Low-latency Pygame mixer (24kHz, 512 buffer)

### Desktop Automation
- **GUI Control**: PyAutoGUI for mouse/keyboard
- **Window Management**: PyGetWindow
- **System Info**: PSUtil for hardware metrics
- **Office Integration**: PyWin32 COM automation

### Design Patterns
- **OOP Architecture**: Modular, extensible class design
- **Async/Await**: Non-blocking voice and TTS operations
- **Action Dispatcher**: Clean separation of concerns

---

## ğŸ“ Project Structure

```
Auto-BOT/
â”œâ”€â”€ app/                      # Main application package
â”‚   â”œâ”€â”€ __init__.py          # Package initialization
â”‚   â”œâ”€â”€ gui.py               # Sci-Fi HUD interface (1100 lines)
â”‚   â”œâ”€â”€ main.py              # Bot engine with async voice loop
â”‚   â”œâ”€â”€ nova_brain.py        # LLM integration layer
â”‚   â”œâ”€â”€ nova_os.py           # OS automation (OOP)
â”‚   â””â”€â”€ nova_actions.py      # Action library (functional)
â”œâ”€â”€ assets/                   # Static resources
â”‚   â””â”€â”€ audio/               # Sound effects
â”œâ”€â”€ main.py                  # Legacy console entry point
â”œâ”€â”€ nova_brain.py            # Legacy brain module
â”œâ”€â”€ nova_os.py               # Legacy OS module
â”œâ”€â”€ nova_actions.py          # Legacy actions module
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ build_exe.py             # PyInstaller build script
â”œâ”€â”€ .env.example             # Environment template
â””â”€â”€ README.md                # Documentation
```

---

## ğŸ”§ Configuration

### Environment Variables

```bash
# .env
GROQ_API_KEY=your_api_key_here
```

### Extending the Bot

**Add Custom Sites** (`nova_actions.py`):
```python
KNOWN_SITES = {
    "github": "github.com",
    "mysite": "example.com",
}
```

**Add Custom Protocols** (`nova_os.py`):
```python
def protocol_custom(self):
    self.launch_app("code")
    self.open_browser("localhost:3000")
```

---

## ğŸ­ Building Executable

```bash
# Install PyInstaller
pip install pyinstaller

# Build standalone EXE
python build_exe.py

# Output: dist/Auto-BOT.exe
```

---

## ğŸ“Š Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| `pyautogui` | â‰¥0.9.54 | GUI automation |
| `pygetwindow` | â‰¥0.0.9 | Window management |
| `psutil` | â‰¥5.9.0 | System monitoring |
| `pygame` | â‰¥2.5.0 | Audio playback |
| `SpeechRecognition` | â‰¥3.10.0 | Voice recognition |
| `edge-tts` | â‰¥6.1.0 | Text-to-speech |
| `groq` | â‰¥0.4.0 | LLM API client |
| `customtkinter` | â‰¥5.2.0 | Modern UI widgets |
| `pywin32` | â‰¥306 | Windows COM automation |

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Google Speech Recognition** - Voice input processing
- **Microsoft Edge TTS** - Natural text-to-speech
- **Groq** - Lightning-fast LLM inference
- **PyAutoGUI** - Cross-platform GUI automation

---

<p align="center">
  <strong>Built with â¤ï¸ for automation enthusiasts</strong>
</p>

<p align="center">
  <a href="https://github.com/YOUR_USERNAME/Auto-BOT/issues">Report Bug</a>
  Â·
  <a href="https://github.com/YOUR_USERNAME/Auto-BOT/issues">Request Feature</a>
</p>
